# Web Scraper Suite

Suite compl√®te d'outils de scraping web avec interface graphique moderne pour l'extraction, l'organisation et l'export de donn√©es web.

## üöÄ Fonctionnalit√©s

### Scraper de Site
- **Exploration automatique** : Crawling r√©cursif avec d√©tection sitemap XML
- **Filtrage intelligent** : Exclusion automatique des ressources statiques
- **Respect robots.txt** : D√©tection et respect des directives de crawling
- **Threading optimis√©** : Scraping parall√®le avec gestion des sessions HTTP
- **Limitation configurable** : Contr√¥le du nombre maximum d'URLs

### Extracteur de Dates
- **Patterns avanc√©s** : Support formats fran√ßais/anglais, ISO 8601, m√©tadonn√©es
- **Sources multiples** : META tags, JSON-LD, microdata, contenu textuel
- **Threading haute performance** : Jusqu'√† 50 threads concurrents
- **Pool de sessions** : R√©utilisation des connexions HTTP
- **Extraction URL** : D√©tection dates dans les chemins d'URL

### Organisateur par Dates
- **Structure hi√©rarchique** : Organisation automatique ann√©e/mois
- **Gestion des anomalies** : Dossier s√©par√© pour URLs sans date
- **Statistiques d√©taill√©es** : M√©triques de distribution temporelle
- **Nomenclature fran√ßaise** : Noms de mois localis√©s

### Exporteur CSV
- **Formats multiples** : Export direct ou depuis structure organis√©e
- **Modes flexibles** : Fichier unique ou s√©par√© par ann√©e
- **Format compatible** : D√©limiteur `;`, quotes syst√©matiques
- **Traitement par batch** : Optimisation m√©moire pour gros volumes

### Recherche de Mots-cl√©s
- **Patterns flexibles** : Support expressions exactes avec guillemets
- **Threading avanc√©** : Recherche parall√®le optimis√©e
- **Contextes d'occurrence** : Extraction des passages pertinents
- **Statistiques granulaires** : Compteurs par mot-cl√© et URL

## üèóÔ∏è Architecture

```
web-scraper-suite/
‚îú‚îÄ‚îÄ main.py                     # Point d'entr√©e GUI
‚îú‚îÄ‚îÄ no_console_launcher.py      # Lanceur sans console Windows
‚îú‚îÄ‚îÄ scraper/
‚îÇ   ‚îú‚îÄ‚îÄ site_scraper.py         # Moteur de scraping principal
‚îÇ   ‚îú‚îÄ‚îÄ date_extractor.py       # Extraction dates publication
‚îÇ   ‚îî‚îÄ‚îÄ keyword_searcher.py     # Recherche mots-cl√©s
‚îú‚îÄ‚îÄ organizer/
‚îÇ   ‚îú‚îÄ‚îÄ date_organizer.py       # Organisation hi√©rarchique
‚îÇ   ‚îî‚îÄ‚îÄ csv_exporter.py         # Export CSV multi-formats
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îî‚îÄ‚îÄ modern_interface.py     # Interface graphique moderne
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ common_utils.py         # Utilitaires partag√©s
‚îÇ   ‚îî‚îÄ‚îÄ logger_config.py        # Configuration logging
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ [domaine]/              # Donn√©es organis√©es par domaine
        ‚îú‚îÄ‚îÄ urls.txt
        ‚îú‚îÄ‚îÄ urls-dates.csv
        ‚îî‚îÄ‚îÄ [ann√©e]/
            ‚îî‚îÄ‚îÄ [mois]/
```

## üîß Technologies

- **Python 3.8+** : Langage principal
- **Tkinter/ttk** : Interface graphique native
- **requests** : Client HTTP optimis√©
- **BeautifulSoup4** : Parsing HTML/XML
- **concurrent.futures** : Threading avanc√©
- **tqdm** : Barres de progression
- **dateutil** : Parsing dates flexible
- **fake-useragent** : Rotation User-Agent

## üìä Workflow Standard

```mermaid
graph LR
    A[URL de d√©part] --> B[Site Scraper]
    B --> C[urls.txt]
    C --> D[Date Extractor]
    D --> E[urls-dates.csv]
    E --> F[Date Organizer]
    F --> G[Structure organis√©e]
    G --> H[CSV Exporter]
    H --> I[export.csv]
    
    C --> J[Keyword Searcher]
    J --> K[keyword_results.csv]
```

## üéØ Cas d'Usage

### Veille Technologique
- Extraction automatis√©e de blogs techniques
- Organisation chronologique des articles
- Recherche de technologies sp√©cifiques

### Analyse de Contenu
- Audit SEO avec extraction de m√©tadonn√©es
- Cartographie temporelle de sites d'actualit√©s
- Mining de contenus th√©matiques

### Research Data
- Constitution de corpus temporels
- Extraction de datasets web
- Analyse longitudinale de contenus

## üöÄ D√©marrage Rapide

### Interface Graphique
```bash
python main.py
```

### CLI Direct
```bash
# Scraping
python scraper/site_scraper.py

# Dates
python scraper/date_extractor.py

# Mots-cl√©s
python scraper/keyword_searcher.py
```

### API Programmatique
```python
from scraper.site_scraper import SiteScraper
from scraper.date_extractor import DateExtractor

scraper = SiteScraper("https://example.com", max_urls=5000)
urls = scraper.scrape()

extractor = DateExtractor("urls.txt", max_threads=20)
dates_found, total, output = extractor.run()
```

## ‚ö° Performance

### Optimisations Impl√©ment√©es
- **Pool de sessions HTTP** : R√©utilisation connexions
- **Threading intelligent** : Auto-scaling selon charge syst√®me
- **Batch processing** : Traitement par lots optimis√©
- **Streaming I/O** : Lecture/√©criture non-bloquante
- **Regex pr√©compil√©es** : Patterns de dates cach√©s

### M√©triques Typiques
- **Scraping** : 50-100 pages/seconde (selon site)
- **Extraction dates** : 200-500 URLs/seconde
- **Export CSV** : 10K+ URLs/seconde
- **Recherche mots-cl√©s** : 100-300 pages/seconde

## üîí Conformit√©

### Respect des Standards
- **robots.txt** : Lecture et respect automatique
- **Rate limiting** : D√©lais configurable entre requ√™tes
- **User-Agent rotation** : Simulation de navigateurs r√©els
- **SSL/TLS** : Support HTTPS complet

### Gestion d'Erreurs
- **Retry automatique** : Tentatives multiples sur √©chec
- **Timeout configurables** : √âviter les blocages
- **Logging d√©taill√©** : Tra√ßabilit√© compl√®te des op√©rations
- **Fallback gracieux** : D√©gradation progressive sur erreurs

## üìà Monitoring

### M√©triques en Temps R√©el
- **Progression** : Barres de progression avec ETA
- **Vitesse** : Pages/seconde instantan√©e
- **Taux de succ√®s** : Pourcentage de r√©ussite
- **Statistiques d√©taill√©es** : Export JSON automatique

### Logs Structur√©s
```
2024-06-30 15:30:25 - INFO - SiteScraper - URLs trouv√©es: 1247
2024-06-30 15:30:26 - INFO - DateExtractor - Dates extraites: 892/1247 (71.5%)
2024-06-30 15:30:27 - INFO - URLDateOrganizer - Organisation: 15 ann√©es, 180 mois
```

## üé® Interface Moderne

### Design System
- **Material Design** : Palette de couleurs coh√©rente
- **Responsive Layout** : Adaptation automatique r√©solution
- **Dark Mode Ready** : Support th√®me sombre
- **Tooltips contextuelles** : Aide int√©gr√©e
- **Notifications** : Feedback utilisateur en temps r√©el

### UX Optimis√©e
- **Workflow guid√©** : Suggestions d'√©tapes suivantes
- **Validation temps r√©el** : V√©rification inputs
- **Raccourcis clavier** : Navigation rapide
- **Historique** : Restauration sessions pr√©c√©dentes

## üìö Documentation

### API Reference
Chaque module expose une API coh√©rente avec callbacks de progression :
```python
def run(self, progress_callback=None):
    # progress_callback(current, total, message)
```

### Configuration Avanc√©e
```python
# Headers personnalis√©s
headers = get_random_headers()
headers.update({'Custom-Header': 'Value'})

# Patterns de dates personnalis√©s
custom_patterns = [r'(\d{4})/(\d{2})/(\d{2})']

# Threading adaptatif
max_threads = min(20, os.cpu_count() * 2)
```

## ü§ù Contribution

### Architecture Modulaire
- **Plugins syst√®me** : Extensibilit√© par modules
- **Interfaces standardis√©es** : Contrats API coh√©rents
- **Tests int√©gr√©s** : Couverture des cas critiques
- **Documentation inline** : Docstrings compl√®tes

### Standards Code
- **PEP 8** : Style guide Python
- **Type hints** : Annotations de types
- **Error handling** : Gestion d'exceptions robuste
- **Logging uniforme** : Standards de traces

## üìÑ Licence

MIT License - Voir fichier LICENSE pour d√©tails complets.

---

**üîó Liens Utiles**
- [Guide Installation](INSTALL.md)
- [Documentation API](docs/api.md)
- [Exemples d'Usage](examples/)
- [Troubleshooting](docs/troubleshooting.md)